{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $N$ (Number of data points)\n",
    "2. $mx_{1}, vx_{1}, my_{1}, vy_{1}, mx_{2}, vx_{2}, my_{2}, vy_{2}$ ($m$:mean, $v$ variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_case(mode):\n",
    "    if mode == 'case 1':      \n",
    "        # Case 1\n",
    "        N = 50\n",
    "        mx1=my1 = 1\n",
    "        mx2=my2 = 10\n",
    "        vx1=vy1=vx2=vy2 = 2\n",
    "    if mode == 'case 2':\n",
    "        # case 2\n",
    "        N = 50\n",
    "        mx1=my1=1\n",
    "        mx2=my2=3\n",
    "        vx1=vy1=2\n",
    "        vx2=vy2=4\n",
    "    return mx1, my1, mx2, my2, vx1, vy1, vx2, vy2, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx1, my1, mx2, my2, vx1, vy1, vx2, vy2, N = switch_case('case 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate $n$ data point $D1 = (x_{1}, y_{1}), (x_{2}, y_{2}), ..., (x_{n}, y_{n})$, where $x$ and $y$ are independently samples from $N(mx_{1}, vx_{1})$ and $N(my_{1}, vy_{1})$ respectively.\n",
    "2. Generate $n$ data point $D2 = (x_{1}, y_{1}), (x_{2}, y_{2}), ..., (x_{n}, y_{n})$, where $x$ and $y$ are independently samples from $N(mx_{2}, vx_{2})$ and $N(my_{2}, vy_{2})$ respectively.\n",
    "3. Use Logistic regression to  separate $D1$ and $D2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_gaussian_data_generator(m, s):    \n",
    "    # Box-Muller method\n",
    "    U = np.random.uniform(0,1)\n",
    "    V = np.random.uniform(0,1)\n",
    "    Z = np.sqrt(-2*np.log(U))*math.cos(2*math.pi*V)\n",
    "    \n",
    "    data = m + s**0.5*Z # output\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design matrix, extract the $x $ item of the mathematical formula into matrix form, the number of samples in the homework is 50, and then stack D1 and D2, so we will have 100 items of x term data, the dimension of the matrix is ​​$50\\times3$<br>\n",
    "$X = \\begin{bmatrix} 1 & x_{11}& x_{12} & ...&x_{1n}\\\\ 1&x_{21}&x_{22}&...&x_{2n} \\\\ ...&...&...&...&... \\\\ 1&x_{m1}&x_{m2}&...&x_{mn}\\end{bmatrix}$<br>\n",
    "\n",
    "Y here is the category, and we first classify D1 and D2 into 0 and 1 categories respectively.<br>\n",
    "$Y = \\begin{bmatrix}Y1\\\\Y2\\\\...\\\\Y3\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = []\n",
    "D2 = []\n",
    "def to_X(D1, D2):\n",
    "    X = np.ones((2 * len(D1), 3))\n",
    "    X[:, 1:] = np.vstack((D1,D2))\n",
    "    return X\n",
    "\n",
    "def to_y(N):\n",
    "    y = np.zeros((2 * N, 1))\n",
    "    y[N:] = np.ones((N, 1))\n",
    "    return y\n",
    "\n",
    "for i in range(N):\n",
    "    D1.append(((univariate_gaussian_data_generator(mx1, vx1)), univariate_gaussian_data_generator(my1, vy1)))\n",
    "    D2.append(((univariate_gaussian_data_generator(mx2, vx2)), univariate_gaussian_data_generator(my2, vy2)))\n",
    "\n",
    "X = to_X(D1,D2)\n",
    "y = to_y(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_{j+1} = x_{j} - \\lambda \\frac{df(x)}{dx} \\\\ W_{j+1} = W_{j} - \\lambda \\frac{d(likelihood)}{dW} \\\\ W_{j+1} = W_{j} - \\lambda \\sum_{i=1}^{m}x_{i}(\\frac{1}{1+e^{-W^{T}_{n}x_{i}}}-Y_{i})$<br>\n",
    "Final formula:<br>\n",
    "$W_{j+1} = W_{j} - \\lambda X^{T}(f(W^{T}x)-Y)$<br>\n",
    "where $f(W^{T}x) = \\begin{bmatrix}\\frac{1}{1+e^{-W^{T}_{j}x_{1}}}\\\\\\frac{1}{1+e^{-W^{T}_{j}x_{2}}}\\\\...\\\\\\frac{1}{1+e^{-W^{T}_{j}x_{m}}}\\end{bmatrix}$<br>\n",
    "The first time I don't know $W_{j}$ , so first create a $3\\times1$ matrix, and also create the updated $W_{j+1}$\n",
    "\n",
    "Create a matrix to store the above formula $f(W^{T}x)$ , this seems to be a sigmoid function, so the variable name is taken as sigmoid\n",
    "\n",
    "Due to the matrix content of sigmoid, the value is filled according to $x_{i}$ in the formula, so there are several data in X, and there should be several in cols of sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr=0.001):\n",
    "    w = np.random.rand(3,1)\n",
    "    w_new = np.random.rand(3,1)\n",
    "    cols_X = X.shape[0]\n",
    "    sigmoid = np.zeros((cols_X,1))\n",
    "   \n",
    "    count = 0\n",
    "    while(True):\n",
    "        count += 1\n",
    "        w = w_new\n",
    "        for i in range (100):\n",
    "            sigmoid[i,:] = 1 / (1+np.exp(-w.T@X[i]))\n",
    "            \n",
    "        delta = X.T@(sigmoid-y)\n",
    "        w_new = w - lr*delta\n",
    "        if(np.linalg.norm(w_new-w)<1e-2 or (count>1e4 and np.linalg.norm(w_new-w)<80) or count>1e5):\n",
    "            break\n",
    "        \n",
    "    print('Gradient descent : \\n')\n",
    "    print('w:')\n",
    "    print(w_new[0])\n",
    "    print(w_new[1])\n",
    "    print(w_new[2])\n",
    "    \n",
    "    return w_new\n",
    "\n",
    "def predict(X, w):\n",
    "    N = len(X)\n",
    "    predict = np.empty((N,1))\n",
    "    for i in range(N):\n",
    "        predict[i]=0 if X[i]@w<0 else 1\n",
    "    return predict\n",
    "\n",
    "def show_confusion_matrix(y, pred):\n",
    "    TP=TN=FP=FN=0\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if y[i] == 0:\n",
    "            if y[i] == pred[i]:\n",
    "                TN+=1\n",
    "            else:\n",
    "                FP+=1\n",
    "        if y[i] == 1:\n",
    "            if y[i] == pred[i]:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FN+=1\n",
    "    matrix=np.empty((2,2))\n",
    "    matrix[0,0],matrix[0,1],matrix[1,0],matrix[1,1]=TP,FN,FP,TN\n",
    "    print('Confusion Matrix:')\n",
    "    print('               Predict cluster 1  Predict cluster 2')\n",
    "    print('Is cluster 1        {:.0f}               {:.0f}       '.format(matrix[0,0],matrix[0,1]))\n",
    "    print('Is cluster 2        {:.0f}               {:.0f}       '.format(matrix[1,0],matrix[1,1]))\n",
    "    print()\n",
    "    print('Sensitivity (Successfully predict cluster 1): {}'.format(matrix[0,0]/(matrix[0,0]+matrix[1,0])))\n",
    "    print('Specificity (Successfully predict cluster 2): {}'.format(matrix[0,0]/(matrix[0,0]+matrix[0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent : \n",
      "\n",
      "w:\n",
      "[-0.62351721]\n",
      "[0.18999606]\n",
      "[0.3672383]\n",
      "Confusion Matrix:\n",
      "               Predict cluster 1  Predict cluster 2\n",
      "Is cluster 1        44               6       \n",
      "Is cluster 2        22               28       \n",
      "\n",
      "Sensitivity (Successfully predict cluster 1): 0.6666666666666666\n",
      "Specificity (Successfully predict cluster 2): 0.88\n"
     ]
    }
   ],
   "source": [
    "w_g = gradient_descent(X, y)\n",
    "pred_g = predict(X, w_g)\n",
    "show_confusion_matrix(y, pred_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's in logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W_{n+1} = W_{n} - (X^{T}RX)^{-1}X^{T}(f(W^{T}_{n}x)-Y) $ <br>\n",
    "where R is diagonal matrix mxm of$\\frac{e^{-W^{T}_{n}x_{i}}}{(1+e^{-W^{T}x_{i}})^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(X, y, lr=0.001):\n",
    "    n_samples = len(X)\n",
    "    R = np.zeros((n_samples, n_samples))\n",
    "    sigmoid = np.zeros((n_samples,1))\n",
    "    w = np.random.rand(3,1)\n",
    "    w_new = np.random.rand(3,1)\n",
    "    count = 0\n",
    "    while(True):\n",
    "        count += 1\n",
    "        w = w_new\n",
    "        for i in range(n_samples):\n",
    "            sigmoid[i,:] = 1 / (1+np.exp(-w.T@X[i]))\n",
    "            R[i,i] = (np.exp(-w.T@X[i])) / (1 + np.exp(-w.T@X[i]))**2\n",
    "        H = X.T@R@X\n",
    "        \n",
    "        try:\n",
    "            H_inv = np.linalg.inv(H)\n",
    "        except np.linalg.LinAlgError as error:\n",
    "            print(str(error))\n",
    "            print('Hessian matrix non invertible, switch to Gradient descent')\n",
    "        \n",
    "        w_new = w - np.linalg.inv(H)@X.T@(sigmoid-y)\n",
    "        if(np.linalg.norm(w_new-w)<1e-2 or (count>1e4 and np.linalg.norm(w_new-w)<80) or count>1e5):\n",
    "            break\n",
    "        \n",
    "    print(\"Newton's method: \\n\")\n",
    "    print('w:')\n",
    "    print(w_new[0])\n",
    "    print(w_new[1])\n",
    "    print(w_new[2])\n",
    "    return w_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton's method: \n",
      "\n",
      "w:\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "Confusion Matrix:\n",
      "               Predict cluster 1  Predict cluster 2\n",
      "Is cluster 1        50               0       \n",
      "Is cluster 2        50               0       \n",
      "\n",
      "Sensitivity (Successfully predict cluster 1): 0.5\n",
      "Specificity (Successfully predict cluster 2): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "w = newton_method(X, y)\n",
    "pred_newtons = predict(X, w)\n",
    "show_confusion_matrix(y, pred_newtons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ground_truth(D1, D2):\n",
    "    D1 = np.array(D1)\n",
    "    D2 = np.array(D2)\n",
    "    plt.figure()\n",
    "    plt.plot(D1[:,0], D1[:,1],'ro')\n",
    "    plt.plot(D2[:,0], D2[:,1],'bo')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.show()\n",
    "\n",
    "def plt_newtons_result(D1, D2, pred):\n",
    "    C0 = []\n",
    "    C1 = []\n",
    "    D1 = np.array(D1)\n",
    "    D2 = np.array(D2)\n",
    "    src_data = np.vstack((D1,D2))\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == 0:\n",
    "            C0.append(src_data[i]) \n",
    "        else:\n",
    "            C1.append(src_data[i])\n",
    "    \n",
    "    C0 = np.array(C0)\n",
    "    C1 = np.array(C1)\n",
    "    plt.figure()\n",
    "    plt.plot(C0[:,0], C0[:,1],'ro')\n",
    "    plt.plot(C1[:,0], C1[:,1],'bo')\n",
    "    plt.title('Newtons method')\n",
    "    plt.show()\n",
    "    \n",
    "def plt_gradient_descent_result(D1, D2, pred):\n",
    "    C0 = []\n",
    "    C1 = []\n",
    "    D1 = np.array(D1)\n",
    "    D2 = np.array(D2)\n",
    "    src_data = np.vstack((D1,D2))\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == 0:\n",
    "            C0.append(src_data[i]) \n",
    "        else:\n",
    "            C1.append(src_data[i])\n",
    "    \n",
    "    C0 = np.array(C0)\n",
    "    C1 = np.array(C1)\n",
    "    plt.figure()\n",
    "    plt.plot(C0[:,0], C0[:,1],'ro')\n",
    "    plt.plot(C1[:,0], C1[:,1],'bo')\n",
    "    plt.title('Gradient Descent')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c873f5c434ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplot_ground_truth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt_newtons_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_newtons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt_gradient_descent_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-142eafedba8c>\u001b[0m in \u001b[0;36mplt_newtons_result\u001b[1;34m(D1, D2, pred)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mC1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Newtons method'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ground_truth(D1, D2)\n",
    "plt_newtons_result(D1, D2, pred_newtons)\n",
    "plt_gradient_descent_result(D1, D2, pred_g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
